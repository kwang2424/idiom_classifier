{'eval_loss': 0.01465365570038557, 'eval_precision': 0.7781299524564184, 'eval_recall': 0.8911070780399274, 'eval_f1': 0.8307952622673433, 'eval_accuracy': 0.9946487695491018, 'eval_runtime': 54.403, 'eval_samples_per_second': 105.895, 'eval_steps_per_second': 13.253, 'epoch': 1.0}


{'eval_loss': 0.013388736173510551, 'eval_precision': 0.802694679150491, 'eval_recall': 0.9113300492610837, 'eval_f1': 0.8535696940262263, 'eval_accuracy': 0.9952364519002933, 'eval_runtime': 55.59, 'eval_samples_per_second': 103.634, 'eval_steps_per_second': 12.97, 'epoch': 2.0}


{'eval_loss': 0.013457473367452621, 'eval_precision': 0.819000819000819, 'eval_recall': 0.9074410163339383, 'eval_f1': 0.8609556607834696, 'eval_accuracy': 0.9955035802417439, 'eval_runtime': 55.4534, 'eval_samples_per_second': 103.889, 'eval_steps_per_second': 13.002, 'epoch': 3.0}

these are some data when training the model.

This model actually seems not very well, I tried many sentence and it got wrong about 30%ðŸ¤”. 
